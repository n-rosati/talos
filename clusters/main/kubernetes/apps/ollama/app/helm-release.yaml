apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: ollama
  namespace: ollama
spec:
  interval: 2m
  timeout: 20m
  chart:
    spec:
      chart: ollama
      version: 8.30.8
      sourceRef:
        kind: HelmRepository
        name: truecharts
        namespace: flux-system
  install:
    createNamespace: true
    remediation:
      retries: 3
  upgrade:
    cleanupOnFail: true
    remediation:
      retries: 3
  values:
    global:
      stopAll: false
    ingress:
      main:
        enabled: true
        ingressClassName: internal
        hosts:
          - host: ollama.${DOMAIN_0}
            paths:
              - path: /
                pathType: Prefix
        integrations:
          certManager:
            certificateIssuer: le-prod
            enabled: true
    workload:
      main:
        podSpec:
          runtimeClassName: "nvidia"
          containers:
            main:
              resources:
                limits:
                  nvidia.com/gpu: 1
    ollama:
      registration:
        enabled: true
        # admin | user | pending
        def_user_role: "pending"
      stable_diffusion:
        base_url: ""
      whisper:
        model: "base"
      rag:
        # cpu | cuda | mps
        model_device_type: "cuda"
        # embedding model
        model: "all-MiniLM-L6-v2"
    resources:
      requests:
        cpu: 100m
        memory: 2Gi
      limits:
        cpu: null
        memory: 8Gi

